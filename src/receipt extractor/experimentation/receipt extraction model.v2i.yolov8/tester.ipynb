{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/damienmaujean/Library/CloudStorage/OneDrive-Personal/university/MiddleSex University/Year 3/CST3990 Individual Project/receipt extractor/experimentation/receipt extraction model.v2i.yolov8'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOME = os.getcwd()\n",
    "HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('trained_model/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(image : numpy.ndarray):\n",
    "    \"\"\"\n",
    "    Extract text from an image using Tesseract OCR.\n",
    "    \"\"\"\n",
    "    # Read the image\n",
    "    # image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to gray scale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use Tesseract to do OCR on the image\n",
    "    text = pytesseract.image_to_string(gray_image)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/damienmaujean/Library/CloudStorage/OneDrive-Personal/university/MiddleSex University/Year 3/CST3990 Individual Project/receipt extractor/experimentation/quick_test/IMG_20240108_202237.jpg: 640x480 4 dates, 3 item_purshases, 1 shop_informaton, 2 totals, 369.6ms\n",
      "Speed: 1.8ms preprocess, 369.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "1051 421 1651 715\n",
      "\n",
      "\n",
      " shop_informaton \n",
      "\n",
      "\n",
      "Super U - Udi Udis Ltee\n",
      "\n",
      "Cap Tanarin, Tamarin\n",
      "VAT Reg, N° ‘ VAT2008575 |\n",
      "Business Reg, N°; CO6008088\n",
      "Te]:484 0062 Fax: 484 0018\n",
      "\n",
      "961 2728 1630 2808\n",
      "\n",
      "\n",
      " total \n",
      "\n",
      "\n",
      "TOTAL 1447.70\n",
      "\n",
      "955 654 1665 1821\n",
      "\n",
      "\n",
      " item_purshase \n",
      "\n",
      "\n",
      "eee No TOA. SO4 UUTG\n",
      "\n",
      "6091022000134\n",
      "BIO PLAIN VEST Bag X\n",
      "3.000 4,000\n",
      "6009650908357\n",
      "MC CAIN FRENCH STIR\n",
      "609124730010)\n",
      "+CHANT E.PACK CUISS\n",
      "6091001660731\n",
      "+CIDF LARDONS FUMES\n",
      "6091001660731\n",
      "+CIDF LARDONS FUMES\n",
      "5411361091081\n",
      "ARDO RAINBOW RICED\n",
      "6091322040069\n",
      "BKAM POW POULET x4\n",
      "3017760038331\n",
      "LULU LA BARQUETTE ¢\n",
      "8410000810004\n",
      "OREO CLASSIQUE Pock\n",
      "6091009000171\n",
      "+SELECTION EGG X12\n",
      "6091059000947\n",
      "+TROP TUNA CHUNK CH\n",
      "6091059000947\n",
      "\n",
      "+TROP TUNA CHUNK CH\n",
      "\n",
      "12.00\n",
      "160.00\n",
      "268.00\n",
      "\n",
      "57.00\n",
      "\n",
      "57.00\n",
      "129.35\n",
      "135,00\n",
      "\n",
      "64.30\n",
      "\n",
      "60.00\n",
      "\n",
      "79.50\n",
      "\n",
      "56.10\n",
      "\n",
      "56.10\n",
      "\n",
      "898 3454 1268 3521\n",
      "\n",
      "\n",
      " date \n",
      "\n",
      "\n",
      "Udlt McCue WM)\n",
      "\n",
      "07.11.23 15:44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "file_path = \"/Users/damienmaujean/Library/CloudStorage/OneDrive-Personal/university/MiddleSex University/Year 3/CST3990 Individual Project/receipt extractor/experimentation/quick_test/IMG_20240108_202237.jpg\"\n",
    "\n",
    "# Run your model\n",
    "results = model(file_path)\n",
    "\n",
    "# Dictionary to store highest confidence detection for each class\n",
    "highest_conf_detections = {}\n",
    "for result in results:\n",
    "    for box in result.boxes:\n",
    "        class_label = result.names[int(box.cls)]\n",
    "        conf = box.conf\n",
    "\n",
    "        # Check if this class_label already exists and if this detection has higher confidence\n",
    "        if class_label not in highest_conf_detections or highest_conf_detections[class_label].conf < conf:\n",
    "            highest_conf_detections[class_label] = box\n",
    "\n",
    "# Now process only the detections with highest confidence for each class\n",
    "for class_label, box in highest_conf_detections.items():\n",
    "    image = cv2.imread(file_path)\n",
    "\n",
    "    # Get box coordinates\n",
    "    x1 = int(box.xyxy[0][0])\n",
    "    y1 = int(box.xyxy[0][1])\n",
    "    x2 = int(box.xyxy[0][2])\n",
    "    y2 = int(box.xyxy[0][3])\n",
    "\n",
    "    print(x1, y1, x2, y2)\n",
    "\n",
    "    # Draw rectangle (bounding box)\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    # Put class label with background rectangle\n",
    "    label_size, base_line = cv2.getTextSize(class_label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    y1_label = max(y1, label_size[1] + 10)\n",
    "    cv2.rectangle(image, (x1, y1 - label_size[1] - 10), (x1 + label_size[0], y1), (0, 255, 0), cv2.FILLED)\n",
    "    cv2.putText(image, class_label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "    # Save or show the result\n",
    "    cv2.imwrite(f\"/Users/damienmaujean/Library/CloudStorage/OneDrive-Personal/university/MiddleSex University/Year 3/CST3990 Individual Project/receipt extractor/experimentation/receipt extraction model.v2i.yolov8/annotion_extraction_test/annotated_image_{class_label}.jpg\", image)\n",
    "    # cropped the picture\n",
    "    crop_img = image[y1:y2, x1:x2]\n",
    "    cv2.imwrite(f\"/Users/damienmaujean/Library/CloudStorage/OneDrive-Personal/university/MiddleSex University/Year 3/CST3990 Individual Project/receipt extractor/experimentation/receipt extraction model.v2i.yolov8/annotion_extraction_test/annotated_image_{class_label}_cropped.jpg\", crop_img)\n",
    "\n",
    "    print(f\"\\n\\n {class_label} \\n\\n\")\n",
    "    print(extract_text(crop_img))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "receipt_extractor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
